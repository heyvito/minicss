# frozen_string_literal: true

# Autogenerated code. This code was generated by bin/gen-specs.rb. DO NOT EDIT.
# Edits will be lost once the generator is run again.

RSpec.describe "css-parsing-tests: component_value_list.json" do
  it "parses \"\"" do
    style = ""
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      empty!
    end
  end

  it "parses \"/*/*///** /* **/*//* \"" do
    style = "/*/*///** /* **/*//* "
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      delim "/"
      delim "*"
      delim "/"
    end
  end

  it "parses \"red\"" do
    style = "red"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      ident "red"
    end
  end

  it "parses \"  \\t\\t\\r\\n\\nRed \"" do
    style = "  \t\t\r\n\nRed "
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      delim " "
      ident "Red"
      delim " "
    end
  end

  it "parses \"red/* CDC */-->\"" do
    style = "red/* CDC */-->"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      ident "red"
      delim "-->"
    end
  end

  it "parses \"red-->/* Not CDC */\"" do
    style = "red-->/* Not CDC */"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      ident "red--"
      delim ">"
    end
  end

  it "parses \"\\\\- red0 -red --red -\\\\-red\\\\ blue 0red -0red \\x00red _Red .red r\\u00EAd r\\\\\\u00EAd \\x7F\\u0080\\u0081\"" do
    style = "\\- red0 -red --red -\\-red\\ blue 0red -0red \x00red _Red .red r\u00EAd r\\\u00EAd \x7F\u0080\u0081"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      ident "-"
      delim " "
      ident "red0"
      delim " "
      ident "-red"
      delim " "
      ident "--red"
      delim " "
      ident "--red blue"
      delim " "
      dimension(0, :integer, "red")
      delim " "
      dimension(0, :integer, "red")
      delim " "
      ident "�red"
      delim " "
      ident "_Red"
      delim " "
      delim "."
      ident "red"
      delim " "
      ident "rêd"
      delim " "
      ident "rêd"
      delim " "
      ident "\u007F"
      ident "\u0080\u0081"
    end
  end

  it "parses \"\\\\30red \\\\00030 red \\\\30\\r\\nred \\\\0000000red \\\\1100000red \\\\red \\\\r ed \\\\.red \\\\ red \\\\\\nred \\\\376\\\\37 6\\\\000376\\\\0000376\\\\\"" do
    style = "\\30red \\00030 red \\30\r\nred \\0000000red \\1100000red \\red \\r ed \\.red \\ red \\\nred \\376\\37 6\\000376\\0000376\\"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      ident "0red"
      delim " "
      ident "0red"
      delim " "
      ident "0red"
      delim " "
      ident "�0red"
      delim " "
      ident "�0red"
      delim " "
      ident "red"
      delim " "
      ident "r"
      delim " "
      ident "ed"
      delim " "
      ident ".red"
      delim " "
      ident " red"
      delim " "
      delim "\\"
      delim " "
      ident "red"
      delim " "
      ident "Ͷ76Ͷ76�"
    end
  end

  it "parses \"rgba0('a' rgba1(a b rgba2(rgba3('b\"" do
    style = "rgba0('a' rgba1(a b rgba2(rgba3('b"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      function("rgba0") do
        string "a"
        delim " "
        function("rgba1") do
          ident "a"
          delim " "
          ident "b"
          delim " "
          function("rgba2") do
            function("rgba3") do
              string "b"
              consume_error("eof-in-string")
            end
          end
        end
      end
    end
  end

  it "parses \"rgba0() -rgba() --rgba() -\\\\-rgba() 0rgba() -0rgba() _rgba() .rgba() rgb\\u00E2() \\\\30rgba() rgba () @rgba() #rgba()\"" do
    style = "rgba0() -rgba() --rgba() -\\-rgba() 0rgba() -0rgba() _rgba() .rgba() rgb\u00E2() \\30rgba() rgba () @rgba() #rgba()"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      function("rgba0") do
        empty!
      end
      delim " "
      function("-rgba") do
        empty!
      end
      delim " "
      function("--rgba") do
        empty!
      end
      delim " "
      function("--rgba") do
        empty!
      end
      delim " "
      dimension(0, :integer, "rgba")
      block("(") do
        empty!
      end
      delim " "
      dimension(0, :integer, "rgba")
      block("(") do
        empty!
      end
      delim " "
      function("_rgba") do
        empty!
      end
      delim " "
      delim "."
      function("rgba") do
        empty!
      end
      delim " "
      function("rgb\u00E2") do
        empty!
      end
      delim " "
      function("0rgba") do
        empty!
      end
      delim " "
      ident "rgba"
      delim " "
      block("(") do
        empty!
      end
      delim " "
      at_keyword("rgba")
      block("(") do
        empty!
      end
      delim " "
      hash_keyword("rgba")
      block("(") do
        empty!
      end
    end
  end

  it "parses \"@media0 @-Media @--media @-\\\\-media @0media @-0media @_media @.media @med\\u0130a @\\\\30 media\\\\\"" do
    style = "@media0 @-Media @--media @-\\-media @0media @-0media @_media @.media @med\u0130a @\\30 media\\"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      at_keyword("media0")
      delim " "
      at_keyword("-Media")
      delim " "
      at_keyword("--media")
      delim " "
      at_keyword("--media")
      delim " "
      delim "@"
      dimension(0, :integer, "media")
      delim " "
      delim "@"
      dimension(0, :integer, "media")
      delim " "
      at_keyword("_media")
      delim " "
      delim "@"
      delim "."
      ident "media"
      delim " "
      at_keyword("med\u0130a")
      delim " "
      at_keyword("0media\uFFFD")
    end
  end

  it "parses \"#red0 #-Red #--red #-\\\\-red #0red #-0red #_Red #.red #r\\u00EAd #\\u00EArd #\\\\.red\\\\\"" do
    style = "#red0 #-Red #--red #-\\-red #0red #-0red #_Red #.red #r\u00EAd #\u00EArd #\\.red\\"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      hash_keyword("red0")
      delim " "
      hash_keyword("-Red")
      delim " "
      hash_keyword("--red")
      delim " "
      hash_keyword("--red")
      delim " "
      hash_keyword("0red")
      delim " "
      hash_keyword("-0red")
      delim " "
      hash_keyword("_Red")
      delim " "
      delim "#"
      delim "."
      ident "red"
      delim " "
      hash_keyword("r\u00EAd")
      delim " "
      hash_keyword("\u00EArd")
      delim " "
      hash_keyword(".red\uFFFD")
    end
  end

  it "parses \"p[example=\\\"\\\\\\nfoo(int x) {\\\\\\n   this.x = x;\\\\\\n}\\\\\\n\\\"]\"" do
    style = "p[example=\"\\\nfoo(int x) {\\\n   this.x = x;\\\n}\\\n\"]"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      ident "p"
      block("[") do
        ident "example"
        delim "="
        string "foo(int x) {   this.x = x;}"
      end
    end
  end

  it "parses \"'' 'Lorem \\\"\\u00EEpsum\\\"' 'a\\\\\\nb' 'a\\nb 'eof\"" do
    style = "'' 'Lorem \"\u00EEpsum\"' 'a\\\nb' 'a\nb 'eof"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      string ""
      delim " "
      string "Lorem \"îpsum\""
      delim " "
      string "ab"
      delim " "
      consume_error("bad-string")
      delim " "
      ident "b"
      delim " "
      string "eof"
      consume_error("eof-in-string")
    end
  end

  it "parses \"\\\"\\\" \\\"Lorem '\\u00EEpsum'\\\" \\\"a\\\\\\nb\\\" \\\"a\\nb \\\"eof\"" do
    style = "\"\" \"Lorem '\u00EEpsum'\" \"a\\\nb\" \"a\nb \"eof"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      string ""
      delim " "
      string "Lorem 'îpsum'"
      delim " "
      string "ab"
      delim " "
      consume_error("bad-string")
      delim " "
      ident "b"
      delim " "
      string "eof"
      consume_error("eof-in-string")
    end
  end

  it "parses \"\\\"Lo\\\\rem \\\\130 ps\\\\u m\\\" '\\\\376\\\\37 6\\\\000376\\\\0000376\\\\\"" do
    style = "\"Lo\\rem \\130 ps\\u m\" '\\376\\37 6\\000376\\0000376\\"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      string "Lorem İpsu m"
      delim " "
      string "Ͷ76Ͷ76"
      consume_error("eof-in-string")
    end
  end

  it "parses \"url( '') url('Lorem \\\"\\u00EEpsum\\\"'\\n) url('a\\\\\\nb' ) url('a\\nb) url('eof\"" do
    style = "url( '') url('Lorem \"\u00EEpsum\"'\n) url('a\\\nb' ) url('a\nb) url('eof"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      function("url") do
        delim " "
        string ""
      end
      delim " "
      function("url") do
        string "Lorem \"îpsum\""
        delim " "
      end
      delim " "
      function("url") do
        string "ab"
        delim " "
      end
      delim " "
      function("url") do
        consume_error("bad-string")
        delim " "
        ident "b"
      end
      delim " "
      function("url") do
        string "eof"
        consume_error("eof-in-string")
      end
    end
  end

  it "parses \"url(\"" do
    style = "url("
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      url("")
      consume_error("eof-in-url")
    end
  end

  it "parses \"url( \\t\"" do
    style = "url( \t"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      url("")
      consume_error("eof-in-url")
    end
  end

  it "parses \"url(\\\"\\\") url(\\\"Lorem '\\u00EEpsum'\\\"\\n) url(\\\"a\\\\\\nb\\\" ) url(\\\"a\\nb) url(\\\"eof\"" do
    style = "url(\"\") url(\"Lorem '\u00EEpsum'\"\n) url(\"a\\\nb\" ) url(\"a\nb) url(\"eof"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      function("url") do
        string ""
      end
      delim " "
      function("url") do
        string "Lorem 'îpsum'"
        delim " "
      end
      delim " "
      function("url") do
        string "ab"
        delim " "
      end
      delim " "
      function("url") do
        consume_error("bad-string")
        delim " "
        ident "b"
      end
      delim " "
      function("url") do
        string "eof"
        consume_error("eof-in-string")
      end
    end
  end

  it "parses \"url(\\\"Lo\\\\rem \\\\130 ps\\\\u m\\\") url('\\\\376\\\\37 6\\\\000376\\\\0000376\\\\\"" do
    style = "url(\"Lo\\rem \\130 ps\\u m\") url('\\376\\37 6\\000376\\0000376\\"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      function("url") do
        string "Lorem İpsu m"
      end
      delim " "
      function("url") do
        string "Ͷ76Ͷ76"
        consume_error("eof-in-string")
      end
    end
  end

  it "parses \"URL(foo) Url(foo) \\u00FBrl(foo) url (foo) url\\\\ (foo) url(\\t 'foo' \"" do
    style = "URL(foo) Url(foo) \u00FBrl(foo) url (foo) url\\ (foo) url(\t 'foo' "
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      url("foo")
      delim " "
      url("foo")
      delim " "
      function("\u00FBrl") do
        ident "foo"
      end
      delim " "
      ident "url"
      delim " "
      block("(") do
        ident "foo"
      end
      delim " "
      function("url ") do
        ident "foo"
      end
      delim " "
      function("url") do
        delim " "
        string "foo"
        delim " "
      end
    end
  end

  it "parses \"url('a' b) url('c' d)\"" do
    style = "url('a' b) url('c' d)"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      function("url") do
        string "a"
        delim " "
        ident "b"
      end
      delim " "
      function("url") do
        string "c"
        delim " "
        ident "d"
      end
    end
  end

  it "parses \"url('a\\nb) url('c\\n\"" do
    style = "url('a\nb) url('c\n"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      function("url") do
        consume_error("bad-string")
        delim " "
        ident "b"
      end
      delim " "
      function("url") do
        consume_error("bad-string")
        delim " "
      end
    end
  end

  it "parses \"url() url( \\t) url(\\n Fo\\u00F4\\\\030\\n!\\n) url(\\na\\nb\\n) url(a\\\\ b) url(a(b) url(a\\\\(b) url(a'b) url(a\\\\'b) url(a\\\"b) url(a\\\\\\\"b) url(a\\nb) url(a\\\\\\nb) url(a\\\\a b) url(a\\\\\"" do
    style = "url() url( \t) url(\n Fo\u00F4\\030\n!\n) url(\na\nb\n) url(a\\ b) url(a(b) url(a\\(b) url(a'b) url(a\\'b) url(a\"b) url(a\\\"b) url(a\nb) url(a\\\nb) url(a\\a b) url(a\\"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      url("")
      delim " "
      url("")
      delim " "
      url("Fo\u00F40!")
      delim " "
      consume_error("bad-url")
      delim " "
      url("a b")
      delim " "
      consume_error("bad-url")
      delim " "
      url("a(b")
      delim " "
      consume_error("bad-url")
      delim " "
      url("a'b")
      delim " "
      consume_error("bad-url")
      delim " "
      url("a\"b")
      delim " "
      consume_error("bad-url")
      delim " "
      consume_error("bad-url")
      delim " "
      url("a\nb")
      delim " "
      url("a\uFFFD")
      consume_error("eof-in-url")
    end
  end

  it "parses \"url(\\x00!\\\#$%&*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[]^_`abcdefghijklmnopqrstuvwxyz{|}~\\u0080\\u0081\\u009E\\u009F\\u00A0\\u00A1\\u00A2\"" do
    style = "url(\x00!\#$%&*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[]^_`abcdefghijklmnopqrstuvwxyz{|}~\u0080\u0081\u009E\u009F\u00A0\u00A1\u00A2"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      url("\uFFFD!\#$%&*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[]^_`abcdefghijklmnopqrstuvwxyz{|}~\u0080\u0081\u009E\u009F\u00A0\u00A1\u00A2")
      consume_error("eof-in-url")
    end
  end

  it "parses \"url(\\x01) url(\\x02) url(\\x03) url(\\x04) url(\\x05) url(\\x06) url(\\a) url(\\b) url(\\v) url(\\x0E) url(\\x0F) url(\\x10) url(\\x11) url(\\x12) url(\\x13) url(\\x14) url(\\x15) url(\\x16) url(\\x17) url(\\x18) url(\\x19) url(\\x1A) url(\\e) url(\\x1C) url(\\x1D) url(\\x1E) url(\\x1F) url(\\x7F)\"" do
    style = "url(\x01) url(\x02) url(\x03) url(\x04) url(\x05) url(\x06) url(\a) url(\b) url(\v) url(\x0E) url(\x0F) url(\x10) url(\x11) url(\x12) url(\x13) url(\x14) url(\x15) url(\x16) url(\x17) url(\x18) url(\x19) url(\x1A) url(\e) url(\x1C) url(\x1D) url(\x1E) url(\x1F) url(\x7F)"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      consume_error("bad-url")
      delim " "
      consume_error("bad-url")
      delim " "
      consume_error("bad-url")
      delim " "
      consume_error("bad-url")
      delim " "
      consume_error("bad-url")
      delim " "
      consume_error("bad-url")
      delim " "
      consume_error("bad-url")
      delim " "
      consume_error("bad-url")
      delim " "
      consume_error("bad-url")
      delim " "
      consume_error("bad-url")
      delim " "
      consume_error("bad-url")
      delim " "
      consume_error("bad-url")
      delim " "
      consume_error("bad-url")
      delim " "
      consume_error("bad-url")
      delim " "
      consume_error("bad-url")
      delim " "
      consume_error("bad-url")
      delim " "
      consume_error("bad-url")
      delim " "
      consume_error("bad-url")
      delim " "
      consume_error("bad-url")
      delim " "
      consume_error("bad-url")
      delim " "
      consume_error("bad-url")
      delim " "
      consume_error("bad-url")
      delim " "
      consume_error("bad-url")
      delim " "
      consume_error("bad-url")
      delim " "
      consume_error("bad-url")
      delim " "
      consume_error("bad-url")
      delim " "
      consume_error("bad-url")
      delim " "
      consume_error("bad-url")
    end
  end

  it "parses \"12 +34 -45 .67 +.89 -.01 2.3 +45.0 -0.67\"" do
    style = "12 +34 -45 .67 +.89 -.01 2.3 +45.0 -0.67"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      number 12, :integer
      delim " "
      number 34, :integer
      delim " "
      number -45, :integer
      delim " "
      number 0.67, :number
      delim " "
      number 0.89, :number
      delim " "
      number -0.01, :number
      delim " "
      number 2.3, :number
      delim " "
      number 45, :number
      delim " "
      number -0.67, :number
    end
  end

  it "parses \"12e2 +34e+1 -45E-0 .68e+3 +.79e-1 -.01E2 2.3E+1 +45.0e6 -0.67e0\"" do
    style = "12e2 +34e+1 -45E-0 .68e+3 +.79e-1 -.01E2 2.3E+1 +45.0e6 -0.67e0"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      number 1200, :number
      delim " "
      number 340, :number
      delim " "
      number -45, :number
      delim " "
      number 680, :number
      delim " "
      number 0.079, :number
      delim " "
      number -1, :number
      delim " "
      number 23, :number
      delim " "
      number 45000000, :number
      delim " "
      number -0.67, :number
    end
  end

  it "parses \"3. /* Decimal point must have following digits */\"" do
    style = "3. /* Decimal point must have following digits */"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      number 3, :integer
      delim "."
      delim " "
    end
  end

  it "parses \"3\\\\65-2 /* Scientific notation E can not be escaped */\"" do
    style = "3\\65-2 /* Scientific notation E can not be escaped */"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      dimension(3, :integer, "e-2")
      delim " "
    end
  end

  it "parses \"3e-2.1 /* Integer exponents only */\"" do
    style = "3e-2.1 /* Integer exponents only */"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      number 0.03, :number
      number 0.1, :number
      delim " "
    end
  end

  it "parses \"12% +34% -45% .67% +.89% -.01% 2.3% +45.0% -0.67%\"" do
    style = "12% +34% -45% .67% +.89% -.01% 2.3% +45.0% -0.67%"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      percentage(12, :integer)
      delim " "
      percentage(34, :integer)
      delim " "
      percentage(-45, :integer)
      delim " "
      percentage(0.67, :number)
      delim " "
      percentage(0.89, :number)
      delim " "
      percentage(-0.01, :number)
      delim " "
      percentage(2.3, :number)
      delim " "
      percentage(45, :number)
      delim " "
      percentage(-0.67, :number)
    end
  end

  it "parses \"12e2% +34e+1% -45E-0% .68e+3% +.79e-1% -.01E2% 2.3E+1% +45.0e6% -0.67e0%\"" do
    style = "12e2% +34e+1% -45E-0% .68e+3% +.79e-1% -.01E2% 2.3E+1% +45.0e6% -0.67e0%"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      percentage(1200, :number)
      delim " "
      percentage(340, :number)
      delim " "
      percentage(-45, :number)
      delim " "
      percentage(680, :number)
      delim " "
      percentage(0.079, :number)
      delim " "
      percentage(-1, :number)
      delim " "
      percentage(23, :number)
      delim " "
      percentage(45000000, :number)
      delim " "
      percentage(-0.67, :number)
    end
  end

  it "parses \"12\\\\% /* Percent sign can not be escaped */\"" do
    style = "12\\% /* Percent sign can not be escaped */"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      dimension(12, :integer, "%")
      delim " "
    end
  end

  it "parses \"12px +34px -45px .67px +.89px -.01px 2.3px +45.0px -0.67px\"" do
    style = "12px +34px -45px .67px +.89px -.01px 2.3px +45.0px -0.67px"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      dimension(12, :integer, "px")
      delim " "
      dimension(34, :integer, "px")
      delim " "
      dimension(-45, :integer, "px")
      delim " "
      dimension(0.67, :number, "px")
      delim " "
      dimension(0.89, :number, "px")
      delim " "
      dimension(-0.01, :number, "px")
      delim " "
      dimension(2.3, :number, "px")
      delim " "
      dimension(45, :number, "px")
      delim " "
      dimension(-0.67, :number, "px")
    end
  end

  it "parses \"12e2px +34e+1px -45E-0px .68e+3px +.79e-1px -.01E2px 2.3E+1px +45.0e6px -0.67e0px\"" do
    style = "12e2px +34e+1px -45E-0px .68e+3px +.79e-1px -.01E2px 2.3E+1px +45.0e6px -0.67e0px"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      dimension(1200, :number, "px")
      delim " "
      dimension(340, :number, "px")
      delim " "
      dimension(-45, :number, "px")
      delim " "
      dimension(680, :number, "px")
      delim " "
      dimension(0.079, :number, "px")
      delim " "
      dimension(-1, :number, "px")
      delim " "
      dimension(23, :number, "px")
      delim " "
      dimension(45000000, :number, "px")
      delim " "
      dimension(-0.67, :number, "px")
    end
  end

  it "parses \"12red0 12.0-red 12--red 12-\\\\-red 120red 12-0red 12\\x00red 12_Red 12.red 12r\\u00EAd\"" do
    style = "12red0 12.0-red 12--red 12-\\-red 120red 12-0red 12\x00red 12_Red 12.red 12r\u00EAd"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      dimension(12, :integer, "red0")
      delim " "
      dimension(12, :number, "-red")
      delim " "
      dimension(12, :integer, "--red")
      delim " "
      dimension(12, :integer, "--red")
      delim " "
      dimension(120, :integer, "red")
      delim " "
      number 12, :integer
      dimension(0, :integer, "red")
      delim " "
      dimension(12, :integer, "\uFFFDred")
      delim " "
      dimension(12, :integer, "_Red")
      delim " "
      number 12, :integer
      delim "."
      ident "red"
      delim " "
      dimension(12, :integer, "r\u00EAd")
    end
  end

  it "parses \"u+1 U+10 U+100 U+1000 U+10000 U+100000 U+1000000\"" do
    style = "u+1 U+10 U+100 U+1000 U+10000 U+100000 U+1000000"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      unicode_range(1, 1)
      delim " "
      unicode_range(16, 16)
      delim " "
      unicode_range(256, 256)
      delim " "
      unicode_range(4096, 4096)
      delim " "
      unicode_range(65536, 65536)
      delim " "
      unicode_range(1048576, 1048576)
      delim " "
      unicode_range(1048576, 1048576)
      number 0, :integer
    end
  end

  it "parses \"u+? u+1? U+10? U+100? U+1000? U+10000? U+100000?\"" do
    style = "u+? u+1? U+10? U+100? U+1000? U+10000? U+100000?"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      unicode_range(0, 15)
      delim " "
      unicode_range(16, 31)
      delim " "
      unicode_range(256, 271)
      delim " "
      unicode_range(4096, 4111)
      delim " "
      unicode_range(65536, 65551)
      delim " "
      unicode_range(1048576, 1048591)
      delim " "
      unicode_range(1048576, 1048576)
      delim "?"
    end
  end

  it "parses \"u+?? U+1?? U+10?? U+100?? U+1000?? U+10000??\"" do
    style = "u+?? U+1?? U+10?? U+100?? U+1000?? U+10000??"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      unicode_range(0, 255)
      delim " "
      unicode_range(256, 511)
      delim " "
      unicode_range(4096, 4351)
      delim " "
      unicode_range(65536, 65791)
      delim " "
      unicode_range(1048576, 1048831)
      delim " "
      unicode_range(1048576, 1048591)
      delim "?"
    end
  end

  it "parses \"u+??? U+1??? U+10??? U+100??? U+1000???\"" do
    style = "u+??? U+1??? U+10??? U+100??? U+1000???"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      unicode_range(0, 4095)
      delim " "
      unicode_range(4096, 8191)
      delim " "
      unicode_range(65536, 69631)
      delim " "
      unicode_range(1048576, 1052671)
      delim " "
      unicode_range(1048576, 1048831)
      delim "?"
    end
  end

  it "parses \"u+???? U+1???? U+10???? U+100????\"" do
    style = "u+???? U+1???? U+10???? U+100????"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      unicode_range(0, 65535)
      delim " "
      unicode_range(65536, 131071)
      delim " "
      unicode_range(1048576, 1114111)
      delim " "
      unicode_range(1048576, 1052671)
      delim "?"
    end
  end

  it "parses \"u+????? U+1????? U+10?????\"" do
    style = "u+????? U+1????? U+10?????"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      unicode_range(0, 1048575)
      delim " "
      unicode_range(1048576, 2097151)
      delim " "
      unicode_range(1048576, 1114111)
      delim "?"
    end
  end

  it "parses \"u+?????? U+1??????\"" do
    style = "u+?????? U+1??????"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      unicode_range(0, 16777215)
      delim " "
      unicode_range(1048576, 2097151)
      delim "?"
    end
  end

  it "parses \"u+1-2 U+100000-2 U+1000000-2 U+10-200000\"" do
    style = "u+1-2 U+100000-2 U+1000000-2 U+10-200000"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      unicode_range(1, 2)
      delim " "
      unicode_range(1048576, 2)
      delim " "
      unicode_range(1048576, 1048576)
      number 0, :integer
      number -2, :integer
      delim " "
      unicode_range(16, 2097152)
    end
  end

  it "parses \"\\u00F9+12 \\u00DC+12 u +12 U+ 12 U+12 - 20 U+1?2 U+1?-50\"" do
    style = "\u00F9+12 \u00DC+12 u +12 U+ 12 U+12 - 20 U+1?2 U+1?-50"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      ident "ù"
      number 12, :integer
      delim " "
      ident "Ü"
      number 12, :integer
      delim " "
      ident "u"
      delim " "
      number 12, :integer
      delim " "
      ident "U"
      delim "+"
      delim " "
      number 12, :integer
      delim " "
      unicode_range(18, 18)
      delim " "
      delim "-"
      delim " "
      number 20, :integer
      delim " "
      unicode_range(16, 31)
      number 2, :integer
      delim " "
      unicode_range(16, 31)
      number -50, :integer
    end
  end

  it "parses \"~=|=^=$=*=||<!------> |/**/| ~/**/=\"" do
    style = "~=|=^=$=*=||<!------> |/**/| ~/**/="
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      delim "~"
      delim "="
      delim "|"
      delim "="
      delim "^"
      delim "="
      delim "$"
      delim "="
      delim "*"
      delim "="
      delim "|"
      delim "|"
      delim "<!--"
      ident "----"
      delim ">"
      delim " "
      delim "|"
      delim "|"
      delim " "
      delim "~"
      delim "="
    end
  end

  it "parses \"a:not([href^=http\\\\:],  [href ^=\\t'https\\\\:'\\n]) { color: rgba(0%, 100%, 50%); }\"" do
    style = "a:not([href^=http\\:],  [href ^=\t'https\\:'\n]) { color: rgba(0%, 100%, 50%); }"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      ident "a"
      delim ":"
      function("not") do
        block("[") do
          ident "href"
          delim "^"
          delim "="
          ident "http:"
        end
        delim ","
        delim " "
        block("[") do
          ident "href"
          delim " "
          delim "^"
          delim "="
          delim " "
          string "https:"
          delim " "
        end
      end
      delim " "
      block("{") do
        delim " "
        ident "color"
        delim ":"
        delim " "
        function("rgba") do
          percentage(0, :integer)
          delim ","
          delim " "
          percentage(100, :integer)
          delim ","
          delim " "
          percentage(50, :integer)
        end
        delim ";"
        delim " "
      end
    end
  end

  it "parses \"@media print { (foo]{bar) }baz\"" do
    style = "@media print { (foo]{bar) }baz"
    tok = TinyCSS::CSS::Tokenizer.new(style, allow_unicode_ranges: true)
    tok.tokenize
    par = TinyCSS::CSS::Parser.new(tok.tokens)
    sheet = par.parse_component_value_list
    r = TinyCSS::AST.convert(sheet)

    match_ast(r) do
      at_keyword("media")
      delim " "
      ident "print"
      delim " "
      block("{") do
        delim " "
        block("(") do
          ident "foo"
          delim "]"
          block("{") do
            ident "bar"
            delim ")"
            delim " "
          end
          ident "baz"
        end
      end
    end
  end

end